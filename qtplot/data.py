import os
import logging
from collections import OrderedDict
import mmap
import numpy as np
import math
from scipy import ndimage, interpolate, io
from scipy.spatial import qhull
from pandas.io.api import read_table
import pandas as pd

from .util import FixedOrderFormatter, eng_format

logger = logging.getLogger(__name__)


class DatFile:
    """ Class which contains the column based DataFrame of the data. """

    def __init__(self, main):
        self.filename = None
        self.timestamp = ''
        self.ids = []#for qtlab data, ids and labels are the same.
        self.labels = []
        self.shape = []#(size1,size2,...)
        self.ndim = 0
        self.qtlab_settings = OrderedDict()
        self.data = None
        self.main = main
        self.a3_sp = ''#setpoint of axis 3, the axis perpendicular to screen
    
    def update_file(self, filename):
        if self.filename != filename:
            logger.info('Loading a new file: %s' %filename)
            if self.data is not None:
                del self.data
            self.__init__(self.main)
            self.filename = filename
            self.load_qtlab_settings()# load .set file
            self.load_metadata()# load metadata, for .mtx files, data are loaded at this step
            self.load_data()# load data
            return True#new file
        else:
            self.load_data()# load data
            return False#old file

    def load_data(self):
        try:
            if self.filename.endswith('.npy'):
                if self.data is None:
                    self.data = np.load(self.filename, mmap_mode='r')
            elif self.filename.endswith('.mtx'):
                pass#data is imported in self.load_metadata()
            else:
                self.data = read_table(self.filename, comment='#', sep='\t', header=None).values
            if len(self.data.shape)!=2 or self.data.shape[1]!=len(self.ids):
                self.data = None
                logger.warning('DatFile: Data shape does not match ids. Return None data')
        except Exception, e:
            self.data = None
            logger.warning('DatFile: Failed to load data: %s'%e)
    
    def load_metadata(self):
        if self.filename.endswith('.npy'):
            meta_filename = self.filename[:-3]+'meta.txt'# for .npy data
        else:
            meta_filename = self.filename# for '.dat data'
        if not os.path.exists(meta_filename):
            logger.warning('DatFile: no meta file')
            return
        with open(meta_filename, 'rb') as f:
            first_line = f.readline().rstrip('\n\t\r')
            # Test whether the file is generated by qtlab or qcodes
            if first_line.startswith('# Filename: '):#QTLab files, for .dat or .npy
                for line in f:
                    line = line.rstrip('\n\t\r')
                    if line.startswith('# Timestamp: '):
                        self.timestamp = line.split(': ', 1)[1]
                    elif line.startswith('#\tname'):
                        name = line.split(': ', 1)[1]
                        self.ids.append(name)
                        self.labels.append(name)
                    elif line.startswith('#\tsize'):
                        size = int(line.split(': ', 1)[1])
                        self.shape = self.shape + [size]
                    # When a line starts with a number we reached the data
                    if len(line) > 0 and line[0] != '#':
                        break
                
            elif first_line.startswith('Units'):#MTX file
                _ = first_line.split(',') 
                self.ids = [x.strip() for x in [_[2],_[5],_[8],_[1]]]
                self.labels = self.ids
                
                s_line = f.readline()
                size_list = s_line.split(' ')
                self.shape = [int(x) for x in size_list[0:3]]

                x = np.linspace(float(_[3]),float(_[4]),self.shape[0])
                y = np.linspace(float(_[6]),float(_[7]),self.shape[1])
                z = np.linspace(float(_[9]),float(_[10]),self.shape[2])
                z,y,x = np.meshgrid(z,y,x,indexing='ij')

                dtp = np.float64 if int(size_list[3]) == 8 else np.float32
                w = np.fromfile(f,dtype=dtp).reshape(self.shape)
                self.data = np.vstack((x.ravel(),y.ravel(),z.ravel(),w.ravel('F'))).T
                
            if len(self.shape)<3:
                self.shape += [1]*(3-len(self.shape))

            self.ndim = sum(d > 1 for d in self.shape)
            if self.shape[2]>1:
                self.main.cb_a3.setStyleSheet("background-color:#cfc;")
            else:
                self.main.cb_a3.setStyleSheet("background-color:#eee;")      

    def load_qtlab_settings(self):
        path, ext = os.path.splitext(self.filename)
        settings_file = path + '.set'
        if os.path.exists(settings_file):
            with open(settings_file) as f:
                lines = f.readlines()

            current_instrument = None
            for line in lines:
                line = line.rstrip('\n\t\r')
                if line == '':
                    continue
                if not line.startswith('\t'):
                    name, value = line.split(': ', 1)
                    if (line.startswith('Filename: ') or
                       line.startswith('Timestamp: ')):
                        self.qtlab_settings.update([(name, value)])
                    else:
                        current_instrument = value
                        new = [(current_instrument, OrderedDict())]
                        self.qtlab_settings.update(new)
                else:
                    param, value = line.split(': ', 1)
                    param = param.strip()
                    new = [(param, value)]
                    self.qtlab_settings[current_instrument].update(new)
        else:
            logger.info('Could not find settings file %s' % os.path.split(settings_file)[1])

    def get_column(self, name):
        if name in self.ids:
            return self.data[:, self.ids.index(name)]
        else:
            return None

    def set_column(self, name, values):
        if name in self.ids:
            self.data[:, self.ids.index(name)] = values
        else:
            self.ids.append(name)
            self.labels.append(name)
            self.data = np.hstack((self.data, values[:, np.newaxis]))

    def get_row_info(self, row):
        # Return a dict of all parameter-value pairs in the row
        return OrderedDict(zip(self.ids, self.data[row]))
    
    def get_dim(self):
        a3,_,__ = self.main.get_a3()
        dim_a3 = 0 if self.shape[a3]<2 else 1
        return self.ndim-dim_a3

    def get_data(self, x_name, y_name, z_name, a3, a3index):
        if self.data is None:
            return None
        if self.get_dim()==0:
            logger.error('0 dimensional data!')
            return None
        if x_name == '':
            logger.error('You have to select a parameter for the x-axis')
            return None
        if a3index > self.shape[a3]-1:
            logger.error('axis3 index out of range.')
            return None
        if y_name != '' and self.get_dim()==1:
            logger.warning('Ignoring the y-axis parameter since it is a 1D dataset')
            y_name = ''
        
        n_per_line = self.shape[0]#number per line
        n_per_page = self.shape[0]*self.shape[1]#number per page
        n_dp = self.data.shape[0]#number of datapoints
        n_pg = np.ceil(float(n_dp)/n_per_page)#number of pages
        
        
        pivot = np.empty((4,n_per_page*n_pg))*np.nan#pad with na.nan

        row_numbers = np.arange(n_dp)#n_dp also == len(x_data)
        x_data = self.get_column(x_name)
        y_data = self.get_column(y_name)
        z_data = self.get_column(z_name)
        if y_data is None:
            y_data = np.zeros(n_dp)

        pivot[0,:n_dp] = x_data
        pivot[1,:n_dp] = y_data
        pivot[2,:n_dp] = z_data
        pivot[3,:n_dp] = row_numbers
        pivot = pivot.reshape([4,n_pg]+self.shape[1::-1])

        if a3 == 0:#x_ind=const
            x,y,z,row_numbers = pivot[:,:,:,a3index]
        elif a3 == 1:#y_ind=const
            x,y,z,row_numbers = pivot[:,:,a3index,:]
        elif a3 == 2 or a3==-1:#z_ind=const
            x,y,z,row_numbers = pivot[:,a3index,:,:]
        else:
            return None

        a3_name = self.ids[a3].split('_')[-1][1:-1]
        if a3_name:
            self.a3_sp = '%s: %s'%(a3_name,self.data[row_numbers[0,0],a3])
        else:
            self.a3_sp = ''
        
        nans = np.isnan(row_numbers[:,0])
        x = x[~nans]
        y = y[~nans]
        z = z[~nans]
        row_numbers = row_numbers[~nans]

        return Data2D(x, y, z, row_numbers, x_name, y_name, z_name, self.filename, self.timestamp, self)


def create_kernel(x_dev, y_dev, cutoff, distr):
    distributions = {
        'gaussian': lambda r: np.exp(-(r**2) / 2.0),
        'exponential': lambda r: np.exp(-abs(r) * np.sqrt(2.0)),
        'lorentzian': lambda r: 1.0 / (r**2+1.0),
        'thermal': lambda r: np.exp(r) / (1 * (1+np.exp(r))**2)
    }
    func = distributions[distr]

    hx = np.floor((x_dev * cutoff) / 2.0)
    hy = np.floor((y_dev * cutoff) / 2.0)

    x = np.linspace(-hx, hx, hx * 2 + 1) / x_dev
    y = np.linspace(-hy, hy, hy * 2 + 1) / y_dev

    if x.size == 1: x = np.zeros(1)
    if y.size == 1: y = np.zeros(1)

    xv, yv = np.meshgrid(x, y)

    kernel = func(np.sqrt(xv**2+yv**2))
    kernel /= np.sum(kernel)

    return kernel


class Data2D:
    """
    Class which represents 2d data as two matrices with x and y coordinates
    and one with values.
    """
    def __init__(self, x, y, z, row_numbers=[],
                 x_name='', y_name='', z_name='',
                 filename='', timestamp='', dat_file=None):
        self.x_name, self.y_name, self.z_name = x_name, y_name, z_name
        self.filename, self.timestamp = filename, timestamp
        self.dat_file = dat_file
        # Be careful of Nan.
        # In order to get [[x1,x2,..],[x1,x2,..],..] and [[y1,y1,..],[y2,y2,..],..] or slightly transformed + noisy coordinates
        # Usually xa >> xb ~ 0, yb >> ya ~ 0
        # Sub R plots: xa > xb, yb >> ya ~0 or xa >> xb ~ 0, yb > ya
        # Above two means: xa>xb and yb>ya
        # Sometimes (shifted scan) xa < xb, yb >> ya ~ 0 or xa >> xb ~ 0, yb < ya
        xa = abs(x[0,0]-x[0,-1])
        xb = abs(x[0,0]-x[-1,0])
        ya = abs(y[0,0]-y[0,-1])
        yb = abs(y[0,0]-y[-1,0])
        if (xa<xb and yb<ya) or (xa>xb and yb<ya and yb/ya<xb/xa) or (xa<xb and yb>ya and ya/yb>xa/xb):
            x = x.T
            y = y.T
            z = z.T
            row_numbers = row_numbers.T
        if x[0,0]>x[0,-1]:
            x = np.fliplr(x)
            y = np.fliplr(y)
            z = np.fliplr(z)
            row_numbers = np.fliplr(row_numbers)
        if y[0,0]>y[-1,0]:
            x = np.flipud(x)
            y = np.flipud(y)
            z = np.flipud(z)
            row_numbers = np.flipud(row_numbers)          

        self.x, self.y, self.z = x, y, z
        self.row_numbers = row_numbers                              
        self.tri = None

        # Store column and row averages for linetrace lookup
        self.x_means = np.nanmean(self.x, axis=0)
        self.y_means = np.nanmean(self.y, axis=1)
    
    def save_meta(self,f):
        xlabel, ylabel, zlabel, title = self.dat_file.main.export_widget.get_format_axis_names()
        f.write('# Filename: %s\n' % self.filename)
        f.write('# Timestamp: %s\n\n' % self.timestamp)
        i = 1
        f.write('# Column %d\n' % i)
        f.write('#\tname: %s\n' % xlabel)
        f.write('#\tsize: %d\n' % self.x.shape[1])
        i += 1
        f.write('# Column %d\n' % i)
        f.write('#\tname: %s\n' % ylabel)
        f.write('#\tsize: %d\n' % self.y.shape[0])
        i += 1
        f.write('# Column %d\n' % i)
        f.write('#\tname: %s\n' % zlabel)
        f.write('\n')
        
    def save(self, filename):
        """
        Save the 2D data to a file. The original data can be upto 3D.

        format (str): .npy / .mat / .dat
        """
        _, ext = os.path.splitext(filename)
        if ext == '.npy':
            with open(filename[:-3]+'meta.txt', 'w') as f:
                self.save_meta(f)
            a = np.vstack((self.x.ravel(), self.y.ravel(), self.z.ravel())).T
            np.save(filename, a)
        elif ext == '.mat':
            mat = np.dstack((self.x, self.y, self.z))
            io.savemat(filename, {'data': mat})
        elif ext == '.dat':
            with open(filename, 'w') as f:
                self.save_meta(f)
                # Write formatted data
                a = np.vstack((self.x.ravel(), self.y.ravel(), self.z.ravel()))
                df = pd.DataFrame(a.T)
                df.to_csv(f, sep='\t', float_format='%.12e', index=False,
                          header=False)
        elif ext == '.mtx':
            with open(filename, 'wb') as f:
                xlabel, ylabel, zlabel, title = self.dat_file.main.export_widget.get_format_axis_names()
                xmin = self.x[0,0]
                xmax = self.x[0,-1]
                ymin = self.y[0,0]
                ymax = self.y[-1,0]
                ny, nx = np.shape(self.y)
                f.write('Units, %s,%s, %s, %s,%s, %s, %s,None(qtplot), 0, 1\n'%(zlabel.replace(',','_'),xlabel.replace(',','_'),xmin,xmax,ylabel.replace(',','_'),ymin,ymax))#data_label,x_label,xmin,xmax,ylabel,ymin,ymax
                f.write('%d %d 1 %d\n'%(nx,ny,self.z.dtype.itemsize))#dimensions nx,ny,nz=1,data_element_size
                self.z.T.ravel().tofile(f)

    def set_data(self, x, y, z):
        self.x, self.y, self.z = x, y, z

    def get_limits(self):
        xmin, xmax = np.nanmin(self.x), np.nanmax(self.x)
        ymin, ymax = np.nanmin(self.y), np.nanmax(self.y)
        zmin, zmax = np.nanmin(self.z), np.nanmax(self.z)

        # Thickness for 1d scans, should we do this here or
        # in the drawing code?
        if xmin == xmax:
            xmin, xmax = -1, 1

        if ymin == ymax:
            ymin, ymax = -1, 1

        return xmin, xmax, ymin, ymax, zmin, zmax

    def get_triangulation_coordinates(self):
        if self.tri is None:
            raise Exception('No triangulation has been generated yet')

        x = self.tri.points[:,0]
        y = self.tri.points[:,1]

        xmin, xmax, ymin, ymax, _, _ = self.get_limits()
        x = x * (xmax - xmin) + xmin
        y = y * (ymax - ymin) + ymin

        return x, y

    def generate_triangulation(self):
        xc = self.x.ravel()
        yc = self.y.ravel()
        zc = self.z.ravel()

        # Remove any NaN values as the triangulation can't handle this
        nans = np.isnan(zc)
        xc = xc[~nans]
        yc = yc[~nans]
        self.no_nan_values = zc[~nans]

        # Normalize the coordinates. This improves the triangulation results
        # in cases where the data ranges on both axes are very different
        # in magnitude
        xmin, xmax, ymin, ymax, _, _ = self.get_limits()
        xc = (xc - xmin) / (xmax - xmin)
        yc = (yc - ymin) / (ymax - ymin)

        self.tri = qhull.Delaunay(np.column_stack((xc, yc)))

    def interpolate(self, points):
        """
        Interpolate points on the 2d data.

        points: N x 2 numpy array with (x, y) as rows
        """
        if self.tri is None:
            self.generate_triangulation()

        xmin, xmax, ymin, ymax, _, _ = self.get_limits()
        points[:,0] = (points[:,0] - xmin) / (xmax - xmin)
        points[:,1] = (points[:,1] - ymin) / (ymax - ymin)

        # Find the indices of the simplices (triangle in this case)
        # to which the points belong to
        simplices = self.tri.find_simplex(points)

        # Find the indices of the datapoints belonging to the simplices
        indices = np.take(self.tri.simplices, simplices, axis=0)
        # Also find the transforms
        transforms = np.take(self.tri.transform, simplices, axis=0)

        # Transform from point coords to barycentric coords
        delta = points - transforms[:,2]
        bary = np.einsum('njk,nk->nj', transforms[:,:2,:], delta)

        temp = np.hstack((bary, 1-bary.sum(axis=1, keepdims=True)))

        values = np.einsum('nj,nj->n', np.take(self.no_nan_values, indices), temp)

        #print values[np.any(temp<0, axis=1)]

        # This should put a NaN for points outside of any simplices
        # but is for some reason sometimes also true inside a simplex
        #values[np.any(temp < 0.0, axis=1)] = np.nan

        return values

    def get_sorted_by_coordinates(self):
        """Return the data sorted so that every coordinate increases."""
        x_indices = np.argsort(self.x[0,:])
        y_indices = np.argsort(self.y[:,0])

        x = self.x[:,x_indices]
        y = self.y[y_indices,:]
        z = self.z[:,x_indices][y_indices,:]

        return x, y, z

    def get_quadrilaterals(self, xc, yc):
        """
        In order to generate quads for every datapoint we do the following
        for the x and y coordinates:
        -   Pad the coordinates with a column/row on each side
        -   Add the difference between all the coords divided by 2 to
            the coords, this generates midpoints
        -   Add a row/column at the end to satisfy the 1 larger
            requirements of pcolor
        """

        # If we are dealing with data that is 2-dimensional
        # -2 rows: both coords need non-nan values
        if xc.shape[1] > 1:
            # Pad both sides with a column of interpolated coordinates
            l0, l1 = xc[:,[0]], xc[:,[1]]
            r1, r0 = xc[:,[-2]], xc[:,[-1]]

            # If there are more than 2 columns/rows, we can extrapolate the
            # datapoint coordinates. Else two columns/rows will not be plotted
            # when plotting an incomplete dataset.
            if xc.shape[1] > 2:
                l2 = xc[:,[2]]
                nans = np.isnan(l0)
                l0[nans] = 2*l1[nans] - l2[nans]
                xc[:,[0]] = l0

                r2 = xc[:,[-3]]
                nans = np.isnan(r0)
                r0[nans] = 2*r1[nans] - r2[nans]
                xc[:,[-1]] = r0

            xc = np.hstack((2*l0 - l1, xc, 2*r0 - r1))
            # Create center points by adding the differences divided by 2 to the original coordinates
            x = xc[:,:-1] + np.diff(xc, axis=1) / 2.0
            # Add a row to the bottom so that the x coords have the same dimension as the y coords
            if np.isnan(x[0]).any():
                x = np.vstack((x, x[-1]))
            else:
                x = np.vstack((x[0], x))
        else:
            # If data is 1d, make one axis range from -.5 to .5
            x = np.hstack((xc - 1, xc[:,[0]] + 1))
            # Duplicate the only row/column so that pcolor has something to actually plot
            x = np.vstack((x, x[0]))

        if yc.shape[0] > 1:
            t0, t1 = yc[0], yc[1]
            b1, b0 = yc[-2], yc[-1]

            if yc.shape[0] > 2:
                t2 = yc[2]
                nans = np.isnan(t0)
                t0[nans] = 2*t1[nans] - t2[nans]
                #yc[0] = t0

                b2 = yc[-3]
                nans = np.isnan(b0)
                b0[nans] = 2*b1[nans] - b2[nans]
                #yc[-1] = b0

            yc = np.vstack([2*t0 - t1, yc, 2*b0 - b1])
            y = yc[:-1,:] + np.diff(yc, axis=0) / 2.0

            if np.isnan(y[:,[0]]).any():
                y = np.hstack([y, y[:,[-1]]])
            else:
                y = np.hstack([y[:,[0]], y])
        else:
            y = np.vstack([yc - 1, yc[0] + 1])
            y = np.hstack([y, y[:,[0]]])

        return x, y

    def get_pcolor(self):
        """
        Return a version of the coordinates and values that can be plotted by pcolor, this means:
        -   Points are sorted by increasing coordinates
        -   Quadrilaterals are generated for every datapoint
        -   NaN values are masked to ignore them when plotting

        Can be plotted using matplotlib's pcolor/pcolormesh(*data.get_pcolor())
        """
        x, y = self.get_quadrilaterals(self.x, self.y)

        return tuple(map(np.ma.masked_invalid, [x, y, self.z]))

    def plot(self, fig, ax, cmap='seismic', font_family='', font_size=12,
             tripcolor=False, show_triangulation=False):
        ax.clear()

        x, y, z = self.get_pcolor()

        if type(cmap) != 'str':
            # It's probably a qtplot Colormap
            cmap = cmap.get_mpl_colormap()

        quadmesh = ax.pcolormesh(x, y, z,
                                      cmap=cmap,
                                      rasterized=True)

        #quadmesh.set_clim(self.main.canvas.colormap.get_limits())

        ax.axis('tight')

        ax.set_title(self.filename)
        ax.set_xlabel(self.x_name)
        ax.set_ylabel(self.y_name)

        ax.xaxis.set_major_formatter(FixedOrderFormatter())
        ax.yaxis.set_major_formatter(FixedOrderFormatter())

        cb = fig.colorbar(quadmesh)

        cb.formatter = FixedOrderFormatter('%.0f', 1)
        cb.update_ticks()
        cb.set_label(self.z_name)
        cb.draw_all()

        fig.tight_layout()

        return cb

    def get_column_at(self, x):
        self.x_means = np.nanmean(self.x, axis=0)
        index = np.argmin(np.abs(self.x_means - x))
        return self.y[:,index], self.z[:,index], self.row_numbers[:,index], index

    def get_row_at(self, y):
        self.y_means = np.nanmean(self.y, axis=1)
        index = np.argmin(np.abs(self.y_means - y))
        return self.x[index], self.z[index], self.row_numbers[index], index

    def get_closest_x(self, x_coord):
        return min(self.x[0,:], key=lambda x:abs(x - x_coord))

    def get_closest_y(self, y_coord):
        return min(self.y[:,0], key=lambda y:abs(y - y_coord))

    def flip_axes(self, x_flip, y_flip):
        if x_flip:
            self.x = np.fliplr(self.x)
            self.y = np.fliplr(self.y)
            self.z = np.fliplr(self.z)
            self.row_numbers = np.fliplr(self.row_numbers)

        if y_flip:
            self.x = np.flipud(self.x)
            self.y = np.flipud(self.y)
            self.z = np.flipud(self.z)
            self.row_numbers = np.flipud(self.row_numbers)

    def is_flipped(self):
        x_flip = self.x[0,0] > self.x[0,-1]
        y_flip = self.y[0,0] > self.y[-1,0]

        return x_flip, y_flip

    def copy(self):
        return Data2D(np.copy(self.x), np.copy(self.y), np.copy(self.z), np.copy(self.row_numbers),
                      self.x_name, self.y_name, self.z_name,
                      self.filename, self.timestamp, self.dat_file)

    def abs(self):
        """Take the absolute value of every datapoint."""
        self.z = np.absolute(self.z)

    def autoflip(self):
        """Flip the data so that the X and Y-axes increase to the top and right."""
        self.flip_axes(*self.is_flipped())

    def crop(self, left=0, right=-1, bottom=0, top=-1):
        """Crop a region of the data by the columns and rows. Last value included"""
        if right < 0:
            right = self.z.shape[1] + right + 1
        else:
            right += 1

        if top < 0:
            top = self.z.shape[0] + top + 1
        else:
            top += 1

        if (left < right and bottom < top and
            0 <= left <= self.z.shape[1] and 0 <= right <= self.z.shape[1] and
            0 <= bottom <= self.z.shape[0] and 0 <= top <= self.z.shape[0]):
            self.x = self.x[bottom:top,left:right]
            self.y = self.y[bottom:top,left:right]
            self.z = self.z[bottom:top,left:right]
            self.row_numbers = self.row_numbers[bottom:top,left:right]
        else:
            raise ValueError('Invalid crop parameters')

    def dderiv(self, theta=0.0, method='midpoint'):
        """Calculate the component of the gradient in a specific direction."""
        xdir, ydir = np.cos(theta), np.sin(theta)

        xcomp = self.copy()
        xcomp.xderiv(method=method)
        ycomp = self.copy()
        ycomp.yderiv(method=method)

        if method == 'midpoint':
            xvalues = xcomp.z[:-1,:]
            yvalues = ycomp.z[:,:-1]

            self.set_data(xcomp.x[:-1,:], ycomp.y[:,:-1], xvalues * xdir + yvalues * ydir)
        elif method == '2nd order central diff':
            xvalues = xcomp.z[1:-1,:]
            yvalues = ycomp.z[:,1:-1]

            self.set_data(xcomp.x[1:-1,:], ycomp.y[:,1:-1], xvalues * xdir + yvalues * ydir)

    def equalize(self):
        """Perform histogramic equalization on the image."""
        binn = 65535

        # Create a density histogram with surface area 1
        no_nans = self.z[~np.isnan(self.z)]
        hist, bins = np.histogram(no_nans.flatten(), binn)
        cdf = hist.cumsum()

        cdf = bins[0] + (bins[-1]-bins[0]) * (cdf / float(cdf[-1]))

        new = np.interp(self.z.flatten(), bins[:-1], cdf)
        self.z = np.reshape(new, self.z.shape)

    def even_odd(self, even):
        """Extract even or odd rows, optionally flipping odd rows."""
        indices = np.arange(0, self.z.shape[0], 2)

        if not even:
            indices = np.arange(1, self.z.shape[0], 2)

        self.set_data(self.x[indices], self.y[indices], self.z[indices])
        self.row_numbers = self.row_numbers[indices]

    def flip(self, x_flip, y_flip):
        """Flip the X or Y axes."""
        self.flip_axes(x_flip, y_flip)

    def gradmag(self, method='midpoint'):
        """Calculate the length of every gradient vector."""
        xcomp = self.copy()
        xcomp.xderiv(method=method)
        ycomp = self.copy()
        ycomp.yderiv(method=method)

        if method == 'midpoint':
            xvalues = xcomp.z[:-1,:]
            yvalues = ycomp.z[:,:-1]

            self.set_data(xcomp.x[:-1,:], ycomp.y[:,:-1], np.sqrt(xvalues**2 + yvalues**2))
        elif method == '2nd order central diff':
            xvalues = xcomp.z[1:-1,:]
            yvalues = ycomp.z[:,1:-1]

            self.set_data(xcomp.x[1:-1,:], ycomp.y[:,1:-1], np.sqrt(xvalues**2 + yvalues**2))

    def highpass(self, x_width=3, y_height=3, method='gaussian'):
        """Perform a high-pass filter."""
        kernel = create_kernel(x_width, y_height, 7, method)
        self.z = self.z - ndimage.filters.convolve(self.z, kernel)

    def hist2d(self, min, max, bins):
        """Convert every column into a histogram, default bin amount is sqrt(n)."""
        hist = np.apply_along_axis(lambda x: np.histogram(x, bins=bins, range=(min, max))[0], 0, self.z)

        binedges = np.linspace(min, max, bins + 1)
        bincoords = (binedges[:-1] + binedges[1:]) / 2

        self.x = np.tile(self.x[0,:], (hist.shape[0], 1))
        self.y = np.tile(bincoords[:,np.newaxis], (1, hist.shape[1]))
        self.z = hist

    def interp_grid(self, width, height):
        """Interpolate the data onto a uniformly spaced grid using barycentric interpolation."""
        # NOT WOKRING FOR SOME REASON
        xmin, xmax, ymin, ymax, _, _ = self.get_limits()

        x = np.linspace(xmin, xmax, width)
        y = np.linspace(ymin, ymax, height)
        xv, yv = np.meshgrid(x, y)

        self.x, self.y = xv, yv
        self.z = np.reshape(self.interpolate(np.column_stack((xv.flatten(), yv.flatten()))), xv.shape)

    def interp_x(self, points):
        """Interpolate every row onto a uniformly spaced grid."""
        xmin, xmax, ymin, ymax, _, _ = self.get_limits()

        x = np.linspace(xmin, xmax, points)

        rows = self.z.shape[0]
        values = np.zeros((rows, points))

        for i in range(rows):
            f = interpolate.interp1d(self.x[i], self.z[i],
                                     bounds_error=False, fill_value=np.nan)
            values[i] = f(x)

        y_avg = np.average(self.y, axis=1)[np.newaxis].T

        self.set_data(np.tile(x, (rows,1)), np.tile(y_avg, (1, points)), values)

    def interp_y(self, points):
        """Interpolate every column onto a uniformly spaced grid."""
        xmin, xmax, ymin, ymax, _, _ = self.get_limits()

        y = np.linspace(ymin, ymax, points)[np.newaxis].T

        cols = self.z.shape[1]
        values = np.zeros((points, cols))

        for i in range(cols):
            f = interpolate.interp1d(self.y[:,i].ravel(), self.z[:,i].ravel(),
                                     bounds_error=False, fill_value=np.nan)
            values[:,i] = f(y).ravel()

        x_avg = np.average(self.x, axis=0)

        self.set_data(np.tile(x_avg, (points,1)), np.tile(y, (1,cols)), values)

    def log(self, subtract, min):
        """The base-10 logarithm of every datapoint."""
        minimum = np.nanmin(self.z)

        if subtract:
            #self.z[self.z < 0] = newmin
            self.z += (min - minimum)

        self.z = np.log10(self.z)

    def lowpass(self, x_width=3, y_height=3, method='gaussian'):
        """Perform a low-pass filter."""
        kernel = create_kernel(x_width, y_height, 7, method)
        self.z = ndimage.filters.convolve(self.z, kernel)
        # self.z = np.ma.masked_invalid(self.z) masked array doesn't works with np.tofile() (for saving as .mtx)

    def negate(self):
        """Negate every datapoint."""
        self.z *= -1

    def norm_columns(self):
        """Transform the values of every column so that they use the full colormap."""
        def func(x):
            return (x - np.nanmin(x)) / (np.nanmax(x) - np.nanmin(x))

        self.z = np.apply_along_axis(func, 0, self.z)

    def norm_rows(self):
        """Transform the values of every row so that they use the full colormap."""
        def func(x):
            return (x - np.nanmin(x)) / (np.nanmax(x) - np.nanmin(x))

        self.z = np.apply_along_axis(func, 1, self.z)

    def offset(self, offset=0):
        """Add a value to every datapoint."""
        self.z += offset

    def offset_axes(self, x_offset=0, y_offset=0):
        """Add an offset value to the axes."""
        self.x += x_offset
        self.y += y_offset

    def power(self, power=1):
        """Raise the datapoints to a power."""
        self.z = np.power(self.z, power)

    def scale_axes(self, x_scale=1, y_scale=1):
        """Multiply the axes values by a number."""
        self.x *= x_scale
        self.y *= y_scale

    def scale_data(self, factor):
        """Multiply the datapoints by a number."""
        self.z *= factor

    def sub_linecut(self, type, position):
        """Subtract a horizontal/vertical linecut from every row/column."""
        if type == 'horizontal':
            x, y, row_numbers, index = self.get_row_at(position)
            y = np.tile(self.z[index,:], (self.z.shape[0],1))
        elif type == 'vertical':
            x, y, row_numbers, index = self.get_column_at(position)
            y = np.tile(self.z[:,index][:,np.newaxis], (1, self.z.shape[1]))

        self.z -= y

    def sub_linecut_avg(self, type, position, size):
        """Subtract a horizontal/vertical averaged linecut from every row/column."""
        if size % 2 == 0:
            start, end = -size/2, size/2-1
        else:
            start, end = -(size-1)/2, (size-1)/2

        indices = np.arange(start, end + 1)

        if type == 'horizontal':
            x, y, index = self.get_row_at(position)
            y = np.mean(self.z[index+indices,:], axis=0)
            y = np.tile(y, (self.z.shape[0],1))
        elif type == 'vertical':
            x, y, index = self.get_column_at(position)
            y = np.mean(self.z[:,index+indices][:,np.newaxis], axis=1)
            y = np.tile(y, (1, self.z.shape[1]))

        self.z -= y

    def sub_plane(self, x_slope, y_slope):
        """Subtract a plane with x and y slopes centered in the middle."""
        xmin, xmax, ymin, ymax, _, _ = self.get_limits()

        self.z -= x_slope*(self.x - (xmax - xmin)/2) + y_slope*(self.y - (ymax - ymin)/2)

    def xderiv(self, method='midpoint'):
        """Find the rate of change between every datapoint in the x-direction."""
        if method == 'midpoint':
            dx = np.diff(self.x, axis=1)
            ddata = np.diff(self.z, axis=1)

            self.x = self.x[:,:-1] + dx / 2.0
            self.y = self.y[:,:-1]
            self.z = ddata / dx
        elif method == '2nd order central diff':
            self.z = (self.z[:,2:] - self.z[:,:-2]) / (self.x[:,2:] - self.x[:,:-2])
            self.x = self.x[:,1:-1]
            self.y = self.y[:,1:-1]

    def yderiv(self, method='midpoint'):
        """Find the rate of change between every datapoint in the y-direction."""
        if method == 'midpoint':
            dy = np.diff(self.y, axis=0)
            ddata = np.diff(self.z, axis=0)

            self.x = self.x[:-1,:]
            self.y = self.y[:-1,:] + dy / 2.0
            self.z = ddata / dy
        elif method == '2nd order central diff':
            self.z = (self.z[2:] - self.z[:-2]) / (self.y[2:] - self.y[:-2])
            self.x = self.x[1:-1]
            self.y = self.y[1:-1]
            
    def R_in_R2(self, a_I, a_V, Rin):
        """z = (z*Amp-Rin)/12906.4, Amp = a_V/a_I"""
        R2 = 12906.4#ohm, h/2e^2
        Amp = a_V/a_I
        self.z = (self.z*Amp-Rin)/R2
    
    def G_in_G2(self, a_I, a_V, Rin):
        """z = z*Amp/(1-(z*Amp*Rin))/7.74809e-5. z*Amp: conductance. Amp: a_I/a_V"""
        G2 = 7.74809e-5#ohm^-1, 2e^2/h
        Amp = a_I/a_V
        self.z = self.z*Amp
        self.z = self.z/(1-(self.z*Rin))/G2
        
    def xy_limit(self,xmin,xmax,ymin,ymax):
        '''Crop data to fit x and y axes range'''
        if not np.all(np.isnan([xmin,xmax,ymin,ymax])):
            x1 = 0 if math.isnan(xmin) else np.searchsorted(self.x[0],xmin)
            x2 = -1 if math.isnan(xmax) else np.searchsorted(self.x[0],xmax,'right')-1
            y1 = 0 if math.isnan(ymin) else np.searchsorted(self.y[:,0],ymin)
            y2 = -1 if math.isnan(ymax) else np.searchsorted(self.y[:,0],ymax,'right')-1
            self.crop(x1,x2,y1,y2)
            
    def reverse_odd_rows(self,shift=0):
        """Reverse and shift odd rows. For a meander scan. [1::2, :]->[1::2, ::-1]"""
        self.x[1::2, :] = self.x[1::2, ::-1]
        if shift>0:
            self.z[1::2, :shift] = np.nan
            self.z[1::2, shift:] = self.z[1::2, :shift-1:-1]
        elif shift<0:
            self.z[1::2, shift:] = np.nan
            self.z[1::2, :shift] = self.z[1::2, shift-1::-1]
        else:
            self.z[1::2, :] = self.z[1::2, ::-1]
            
            
        
        